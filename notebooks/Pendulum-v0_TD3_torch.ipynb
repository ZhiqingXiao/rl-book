{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZNjG2KMmyDi"
   },
   "source": [
    "# Use TD3 to Play Pendulum-v0\n",
    "\n",
    "PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocihf3XMmyDk"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import imp\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import pandas as pd\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "imp.reload(logging)\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        stream=sys.stdout, datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:59:01 [INFO] env: <PendulumEnv<Pendulum-v0>>\n",
      "21:59:01 [INFO] action_space: Box(-2.0, 2.0, (1,), float32)\n",
      "21:59:01 [INFO] observation_space: Box(-8.0, 8.0, (3,), float32)\n",
      "21:59:01 [INFO] reward_range: (-inf, inf)\n",
      "21:59:01 [INFO] metadata: {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 30}\n",
      "21:59:01 [INFO] _max_episode_steps: 200\n",
      "21:59:01 [INFO] _elapsed_steps: None\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "env.seed(0)\n",
    "for key in vars(env):\n",
    "    logging.info('%s: %s', key, vars(env)[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxbw9KN3myD2"
   },
   "outputs": [],
   "source": [
    "class DQNReplayer:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = pd.DataFrame(index=range(capacity),\n",
    "                columns=['observation', 'action', 'reward',\n",
    "                'next_observation', 'done'])\n",
    "        self.i = 0\n",
    "        self.count = 0\n",
    "        self.capacity = capacity\n",
    "    \n",
    "    def store(self, *args):\n",
    "        self.memory.loc[self.i] = args\n",
    "        self.i = (self.i + 1) % self.capacity\n",
    "        self.count = min(self.count + 1, self.capacity)\n",
    "        \n",
    "    def sample(self, size):\n",
    "        indices = np.random.choice(self.count, size=size)\n",
    "        return (np.stack(self.memory.loc[indices, field]) for field in\n",
    "                self.memory.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u4kWbfiUmyD6"
   },
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckProcess:\n",
    "    def __init__(self, x0):\n",
    "        self.x = x0\n",
    "\n",
    "    def __call__(self, mu=0., sigma=1., theta=.15, dt=.01):\n",
    "        n = np.random.normal(size=self.x.shape)\n",
    "        self.x += (theta * (mu - self.x) * dt + sigma * np.sqrt(dt) * n)\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcieY0EAmyEJ"
   },
   "outputs": [],
   "source": [
    "class TD3Agent:\n",
    "    def __init__(self, env):\n",
    "        state_dim = env.observation_space.shape[0]\n",
    "        self.action_dim = env.action_space.shape[0]\n",
    "        self.action_low = env.action_space.low[0]\n",
    "        self.action_high = env.action_space.high[0]\n",
    "\n",
    "        self.gamma = 0.99\n",
    "\n",
    "        self.replayer = DQNReplayer(20000)\n",
    "\n",
    "        self.actor_evaluate_net = self.build_net(\n",
    "                input_size=state_dim, hidden_sizes=[32, 64],\n",
    "                output_size=self.action_dim)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_evaluate_net.parameters(), lr=0.001)\n",
    "        self.actor_target_net = copy.deepcopy(self.actor_evaluate_net)\n",
    "\n",
    "        self.critic0_evaluate_net = self.build_net(\n",
    "                input_size=state_dim+self.action_dim, hidden_sizes=[64, 128])\n",
    "        self.critic0_optimizer = optim.Adam(self.critic0_evaluate_net.parameters(), lr=0.001)\n",
    "        self.critic0_loss = nn.MSELoss()\n",
    "        self.critic0_target_net = copy.deepcopy(self.critic0_evaluate_net)\n",
    "\n",
    "        self.critic1_evaluate_net = self.build_net(\n",
    "                input_size=state_dim+self.action_dim, hidden_sizes=[64, 128])\n",
    "        self.critic1_optimizer = optim.Adam(self.critic1_evaluate_net.parameters(), lr=0.001)\n",
    "        self.critic1_loss = nn.MSELoss()\n",
    "        self.critic1_target_net = copy.deepcopy(self.critic1_evaluate_net)\n",
    "        \n",
    "    def build_net(self, input_size, hidden_sizes, output_size=1,\n",
    "            output_activator=None):\n",
    "        layers = []\n",
    "        for input_size, output_size in zip(\n",
    "                [input_size,] + hidden_sizes, hidden_sizes + [output_size,]):\n",
    "            layers.append(nn.Linear(input_size, output_size))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers = layers[:-1]\n",
    "        if output_activator:\n",
    "            layers.append(output_activator)\n",
    "        net = nn.Sequential(*layers)\n",
    "        return net\n",
    "\n",
    "    def reset(self, mode=None):\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "            self.trajectory = []\n",
    "            self.noise = OrnsteinUhlenbeckProcess(np.zeros((self.action_dim,)))\n",
    "\n",
    "    def step(self, observation, reward, done):\n",
    "        state_tensor = torch.as_tensor(observation, dtype=torch.float).unsqueeze(0)\n",
    "        action_tensor = self.actor_evaluate_net(state_tensor)\n",
    "        action = action_tensor.detach().numpy()[0]\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # noisy action\n",
    "            action = (action + self.noise(sigma=0.1)).clip(self.action_low, self.action_high)\n",
    "            \n",
    "            self.trajectory += [observation, reward, done, action]\n",
    "            if len(self.trajectory) >= 8:\n",
    "                state, _, _, action, next_state, reward, done, _ = self.trajectory[-8:]\n",
    "                self.replayer.store(state, action, reward, next_state, done)\n",
    "            \n",
    "            # learn\n",
    "            if self.replayer.count >= 3000:\n",
    "                self.learn()\n",
    "        return action\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def update_net(self, target_net, evaluate_net, learning_rate=0.005):\n",
    "        for target_param, evaluate_param in zip(\n",
    "                target_net.parameters(), evaluate_net.parameters()):\n",
    "            target_param.data.copy_(learning_rate * evaluate_param.data\n",
    "                    + (1 - learning_rate) * target_param.data)\n",
    "\n",
    "    def learn(self):\n",
    "        # replay\n",
    "        states, actions, rewards, next_states, dones = self.replayer.sample(64)\n",
    "        state_tensor = torch.as_tensor(states, dtype=torch.float)\n",
    "        action_tensor = torch.as_tensor(actions, dtype=torch.long)\n",
    "        reward_tensor = torch.as_tensor(rewards, dtype=torch.float)\n",
    "        next_state_tensor = torch.as_tensor(next_states, dtype=torch.float)\n",
    "        done_tensor = torch.as_tensor(dones, dtype=torch.float)\n",
    "        \n",
    "        # learn critic\n",
    "        next_action_tensor = self.actor_target_net(next_state_tensor)\n",
    "        noise_tensor = (0.2 * torch.randn_like(action_tensor, dtype=torch.float))\n",
    "        noisy_next_action_tensor = (next_action_tensor + noise_tensor\n",
    "                    ).clamp(self.action_low, self.action_high)\n",
    "        next_state_action_tensor = torch.cat([next_state_tensor, noisy_next_action_tensor], 1)\n",
    "        next_q0_tensor = self.critic0_target_net(next_state_action_tensor).squeeze(1)\n",
    "        next_q1_tensor = self.critic1_target_net(next_state_action_tensor).squeeze(1)\n",
    "        next_q_tensor = torch.min(next_q0_tensor, next_q1_tensor)\n",
    "        critic_target_tensor = reward_tensor + (1. - done_tensor) * self.gamma * next_q_tensor\n",
    "        critic_target_tensor = critic_target_tensor.detach()\n",
    "        \n",
    "        state_action_tensor = torch.cat([state_tensor, action_tensor], 1)\n",
    "        critic_pred0_tensor = self.critic0_evaluate_net(state_action_tensor).squeeze(1)\n",
    "        critic0_loss_tensor = self.critic0_loss(critic_pred0_tensor, critic_target_tensor)\n",
    "        self.critic0_optimizer.zero_grad()\n",
    "        critic0_loss_tensor.backward() # retain_graph=True)\n",
    "        self.critic0_optimizer.step()\n",
    "        \n",
    "        # state_action_tensor = torch.cat([state_tensor, action_tensor], 1)\n",
    "        critic_pred1_tensor = self.critic1_evaluate_net(state_action_tensor).squeeze(1)\n",
    "        critic1_loss_tensor = self.critic1_loss(critic_pred1_tensor, critic_target_tensor)\n",
    "        self.critic1_optimizer.zero_grad()\n",
    "        critic1_loss_tensor.backward()\n",
    "        self.critic1_optimizer.step()\n",
    "\n",
    "        # learn actor\n",
    "        pred_action_tensor = self.actor_evaluate_net(state_tensor)\n",
    "        pred_action_tensor = pred_action_tensor.clamp(self.action_low, self.action_high)\n",
    "        pred_state_action_tensor = torch.cat([state_tensor, pred_action_tensor], 1)\n",
    "        critic_pred_tensor = self.critic0_evaluate_net(pred_state_action_tensor)\n",
    "        actor_loss_tensor = -critic_pred_tensor.mean()\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss_tensor.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        self.update_net(self.critic0_target_net, self.critic0_evaluate_net)\n",
    "        self.update_net(self.critic1_target_net, self.critic1_evaluate_net)\n",
    "        self.update_net(self.actor_target_net, self.actor_evaluate_net)\n",
    "\n",
    "\n",
    "agent = TD3Agent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:59:02 [INFO] ==== train ====\n",
      "21:59:02 [DEBUG] train episode 0: reward = -1724.11, steps = 200\n",
      "21:59:02 [DEBUG] train episode 1: reward = -1070.40, steps = 200\n",
      "21:59:02 [DEBUG] train episode 2: reward = -1580.51, steps = 200\n",
      "21:59:02 [DEBUG] train episode 3: reward = -1060.82, steps = 200\n",
      "21:59:03 [DEBUG] train episode 4: reward = -1745.79, steps = 200\n",
      "21:59:03 [DEBUG] train episode 5: reward = -1763.42, steps = 200\n",
      "21:59:03 [DEBUG] train episode 6: reward = -949.54, steps = 200\n",
      "21:59:03 [DEBUG] train episode 7: reward = -1768.15, steps = 200\n",
      "21:59:03 [DEBUG] train episode 8: reward = -896.69, steps = 200\n",
      "21:59:04 [DEBUG] train episode 9: reward = -1768.54, steps = 200\n",
      "21:59:04 [DEBUG] train episode 10: reward = -1318.00, steps = 200\n",
      "21:59:04 [DEBUG] train episode 11: reward = -984.80, steps = 200\n",
      "21:59:04 [DEBUG] train episode 12: reward = -1516.38, steps = 200\n",
      "21:59:04 [DEBUG] train episode 13: reward = -1286.60, steps = 200\n",
      "21:59:05 [DEBUG] train episode 14: reward = -859.81, steps = 200\n",
      "21:59:47 [DEBUG] train episode 15: reward = -1497.77, steps = 200\n",
      "22:00:35 [DEBUG] train episode 16: reward = -943.65, steps = 200\n",
      "22:01:20 [DEBUG] train episode 17: reward = -1420.20, steps = 200\n",
      "22:02:03 [DEBUG] train episode 18: reward = -1228.28, steps = 200\n",
      "22:02:46 [DEBUG] train episode 19: reward = -1234.53, steps = 200\n",
      "22:03:28 [DEBUG] train episode 20: reward = -1339.85, steps = 200\n",
      "22:04:12 [DEBUG] train episode 21: reward = -1700.01, steps = 200\n",
      "22:04:54 [DEBUG] train episode 22: reward = -1731.68, steps = 200\n",
      "22:05:37 [DEBUG] train episode 23: reward = -1340.62, steps = 200\n",
      "22:06:19 [DEBUG] train episode 24: reward = -1126.27, steps = 200\n",
      "22:07:02 [DEBUG] train episode 25: reward = -1644.37, steps = 200\n",
      "22:07:46 [DEBUG] train episode 26: reward = -1420.58, steps = 200\n",
      "22:08:30 [DEBUG] train episode 27: reward = -1303.39, steps = 200\n",
      "22:09:14 [DEBUG] train episode 28: reward = -1273.86, steps = 200\n",
      "22:09:57 [DEBUG] train episode 29: reward = -1499.52, steps = 200\n",
      "22:10:42 [DEBUG] train episode 30: reward = -1305.46, steps = 200\n",
      "22:11:26 [DEBUG] train episode 31: reward = -1327.48, steps = 200\n",
      "22:12:11 [DEBUG] train episode 32: reward = -845.90, steps = 200\n",
      "22:12:54 [DEBUG] train episode 33: reward = -1102.09, steps = 200\n",
      "22:13:39 [DEBUG] train episode 34: reward = -1101.26, steps = 200\n",
      "22:14:24 [DEBUG] train episode 35: reward = -1122.43, steps = 200\n",
      "22:15:07 [DEBUG] train episode 36: reward = -1140.86, steps = 200\n",
      "22:15:55 [DEBUG] train episode 37: reward = -1046.36, steps = 200\n",
      "22:16:38 [DEBUG] train episode 38: reward = -914.37, steps = 200\n",
      "22:17:25 [DEBUG] train episode 39: reward = -864.75, steps = 200\n",
      "22:18:11 [DEBUG] train episode 40: reward = -867.16, steps = 200\n",
      "22:18:57 [DEBUG] train episode 41: reward = -1148.65, steps = 200\n",
      "22:19:42 [DEBUG] train episode 42: reward = -702.34, steps = 200\n",
      "22:20:29 [DEBUG] train episode 43: reward = -757.10, steps = 200\n",
      "22:21:15 [DEBUG] train episode 44: reward = -1037.94, steps = 200\n",
      "22:22:00 [DEBUG] train episode 45: reward = -804.83, steps = 200\n",
      "22:22:49 [DEBUG] train episode 46: reward = -849.05, steps = 200\n",
      "22:23:37 [DEBUG] train episode 47: reward = -747.49, steps = 200\n",
      "22:24:25 [DEBUG] train episode 48: reward = -974.06, steps = 200\n",
      "22:25:16 [DEBUG] train episode 49: reward = -923.98, steps = 200\n",
      "22:26:04 [DEBUG] train episode 50: reward = -853.90, steps = 200\n",
      "22:26:50 [DEBUG] train episode 51: reward = -897.35, steps = 200\n",
      "22:27:26 [DEBUG] train episode 52: reward = -882.34, steps = 200\n",
      "22:28:12 [DEBUG] train episode 53: reward = -859.53, steps = 200\n",
      "22:28:59 [DEBUG] train episode 54: reward = -803.30, steps = 200\n",
      "22:29:46 [DEBUG] train episode 55: reward = -741.21, steps = 200\n",
      "22:30:38 [DEBUG] train episode 56: reward = -735.54, steps = 200\n",
      "22:31:38 [DEBUG] train episode 57: reward = -995.49, steps = 200\n",
      "22:32:36 [DEBUG] train episode 58: reward = -1014.01, steps = 200\n",
      "22:33:23 [DEBUG] train episode 59: reward = -868.29, steps = 200\n",
      "22:34:14 [DEBUG] train episode 60: reward = -1032.70, steps = 200\n",
      "22:34:45 [DEBUG] train episode 61: reward = -1096.49, steps = 200\n",
      "22:35:22 [DEBUG] train episode 62: reward = -1121.88, steps = 200\n",
      "22:35:57 [DEBUG] train episode 63: reward = -1013.76, steps = 200\n",
      "22:36:34 [DEBUG] train episode 64: reward = -1066.94, steps = 200\n",
      "22:37:08 [DEBUG] train episode 65: reward = -1167.37, steps = 200\n",
      "22:37:48 [DEBUG] train episode 66: reward = -1061.37, steps = 200\n",
      "22:38:32 [DEBUG] train episode 67: reward = -1072.04, steps = 200\n",
      "22:39:11 [DEBUG] train episode 68: reward = -1001.56, steps = 200\n",
      "22:39:48 [DEBUG] train episode 69: reward = -877.96, steps = 200\n",
      "22:40:24 [DEBUG] train episode 70: reward = -965.50, steps = 200\n",
      "22:41:00 [DEBUG] train episode 71: reward = -892.11, steps = 200\n",
      "22:41:37 [DEBUG] train episode 72: reward = -485.19, steps = 200\n",
      "22:42:11 [DEBUG] train episode 73: reward = -263.52, steps = 200\n",
      "22:42:45 [DEBUG] train episode 74: reward = -383.84, steps = 200\n",
      "22:43:20 [DEBUG] train episode 75: reward = -392.92, steps = 200\n",
      "22:43:55 [DEBUG] train episode 76: reward = -505.31, steps = 200\n",
      "22:44:29 [DEBUG] train episode 77: reward = -388.90, steps = 200\n",
      "22:45:05 [DEBUG] train episode 78: reward = -505.85, steps = 200\n",
      "22:45:40 [DEBUG] train episode 79: reward = -267.63, steps = 200\n",
      "22:46:15 [DEBUG] train episode 80: reward = -380.77, steps = 200\n",
      "22:46:54 [DEBUG] train episode 81: reward = -132.66, steps = 200\n",
      "22:47:30 [DEBUG] train episode 82: reward = -645.14, steps = 200\n",
      "22:48:07 [DEBUG] train episode 83: reward = -389.25, steps = 200\n",
      "22:48:45 [DEBUG] train episode 84: reward = -527.56, steps = 200\n",
      "22:49:23 [DEBUG] train episode 85: reward = -383.00, steps = 200\n",
      "22:49:59 [DEBUG] train episode 86: reward = -763.35, steps = 200\n",
      "22:50:40 [DEBUG] train episode 87: reward = -617.93, steps = 200\n",
      "22:51:25 [DEBUG] train episode 88: reward = -507.06, steps = 200\n",
      "22:52:04 [DEBUG] train episode 89: reward = -498.31, steps = 200\n",
      "22:52:40 [DEBUG] train episode 90: reward = -503.32, steps = 200\n",
      "22:53:17 [DEBUG] train episode 91: reward = -624.02, steps = 200\n",
      "22:53:58 [DEBUG] train episode 92: reward = -616.91, steps = 200\n",
      "22:55:03 [DEBUG] train episode 93: reward = -506.14, steps = 200\n",
      "22:56:40 [DEBUG] train episode 94: reward = -507.51, steps = 200\n",
      "22:58:21 [DEBUG] train episode 95: reward = -836.09, steps = 200\n",
      "22:59:17 [DEBUG] train episode 96: reward = -631.77, steps = 200\n",
      "23:00:03 [DEBUG] train episode 97: reward = -621.76, steps = 200\n",
      "23:00:42 [DEBUG] train episode 98: reward = -628.53, steps = 200\n",
      "23:01:19 [DEBUG] train episode 99: reward = -709.82, steps = 200\n",
      "23:01:53 [DEBUG] train episode 100: reward = -506.48, steps = 200\n",
      "23:02:28 [DEBUG] train episode 101: reward = -503.66, steps = 200\n",
      "23:03:03 [DEBUG] train episode 102: reward = -505.05, steps = 200\n",
      "23:03:38 [DEBUG] train episode 103: reward = -759.25, steps = 200\n",
      "23:04:12 [DEBUG] train episode 104: reward = -625.59, steps = 200\n",
      "23:04:45 [DEBUG] train episode 105: reward = -621.59, steps = 200\n",
      "23:05:19 [DEBUG] train episode 106: reward = -504.77, steps = 200\n",
      "23:05:52 [DEBUG] train episode 107: reward = -615.44, steps = 200\n",
      "23:06:24 [DEBUG] train episode 108: reward = -629.66, steps = 200\n",
      "23:06:56 [DEBUG] train episode 109: reward = -731.98, steps = 200\n",
      "23:07:30 [DEBUG] train episode 110: reward = -511.56, steps = 200\n",
      "23:08:02 [DEBUG] train episode 111: reward = -514.42, steps = 200\n",
      "23:08:34 [DEBUG] train episode 112: reward = -615.49, steps = 200\n",
      "23:09:08 [DEBUG] train episode 113: reward = -585.77, steps = 200\n",
      "23:09:46 [DEBUG] train episode 114: reward = -524.77, steps = 200\n",
      "23:10:29 [DEBUG] train episode 115: reward = -614.63, steps = 200\n",
      "23:11:13 [DEBUG] train episode 116: reward = -631.49, steps = 200\n",
      "23:11:52 [DEBUG] train episode 117: reward = -515.06, steps = 200\n",
      "23:12:26 [DEBUG] train episode 118: reward = -515.33, steps = 200\n",
      "23:12:59 [DEBUG] train episode 119: reward = -509.03, steps = 200\n",
      "23:13:33 [DEBUG] train episode 120: reward = -631.76, steps = 200\n",
      "23:14:05 [DEBUG] train episode 121: reward = -378.59, steps = 200\n",
      "23:14:40 [DEBUG] train episode 122: reward = -382.17, steps = 200\n",
      "23:15:13 [DEBUG] train episode 123: reward = -635.55, steps = 200\n",
      "23:15:47 [DEBUG] train episode 124: reward = -256.92, steps = 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:16:21 [DEBUG] train episode 125: reward = -624.66, steps = 200\n",
      "23:16:54 [DEBUG] train episode 126: reward = -533.41, steps = 200\n",
      "23:17:28 [DEBUG] train episode 127: reward = -517.09, steps = 200\n",
      "23:18:00 [DEBUG] train episode 128: reward = -513.93, steps = 200\n",
      "23:18:33 [DEBUG] train episode 129: reward = -362.91, steps = 200\n",
      "23:19:08 [DEBUG] train episode 130: reward = -290.14, steps = 200\n",
      "23:19:44 [DEBUG] train episode 131: reward = -642.97, steps = 200\n",
      "23:20:19 [DEBUG] train episode 132: reward = -396.22, steps = 200\n",
      "23:20:53 [DEBUG] train episode 133: reward = -283.90, steps = 200\n",
      "23:21:26 [DEBUG] train episode 134: reward = -626.72, steps = 200\n",
      "23:22:00 [DEBUG] train episode 135: reward = -641.76, steps = 200\n",
      "23:22:35 [DEBUG] train episode 136: reward = -380.52, steps = 200\n",
      "23:23:14 [DEBUG] train episode 137: reward = -499.40, steps = 200\n",
      "23:23:50 [DEBUG] train episode 138: reward = -378.34, steps = 200\n",
      "23:24:26 [DEBUG] train episode 139: reward = -513.69, steps = 200\n",
      "23:25:01 [DEBUG] train episode 140: reward = -628.14, steps = 200\n",
      "23:25:36 [DEBUG] train episode 141: reward = -364.33, steps = 200\n",
      "23:26:12 [DEBUG] train episode 142: reward = -510.09, steps = 200\n",
      "23:26:50 [DEBUG] train episode 143: reward = -130.96, steps = 200\n",
      "23:27:26 [DEBUG] train episode 144: reward = -133.86, steps = 200\n",
      "23:28:02 [DEBUG] train episode 145: reward = -259.84, steps = 200\n",
      "23:28:40 [DEBUG] train episode 146: reward = -136.11, steps = 200\n",
      "23:29:18 [DEBUG] train episode 147: reward = -253.34, steps = 200\n",
      "23:29:55 [DEBUG] train episode 148: reward = -137.25, steps = 200\n",
      "23:30:31 [DEBUG] train episode 149: reward = -494.49, steps = 200\n",
      "23:31:04 [DEBUG] train episode 150: reward = -507.06, steps = 200\n",
      "23:31:22 [DEBUG] train episode 151: reward = -405.51, steps = 200\n",
      "23:31:50 [DEBUG] train episode 152: reward = -10.08, steps = 200\n",
      "23:32:04 [DEBUG] train episode 153: reward = -128.16, steps = 200\n",
      "23:32:32 [DEBUG] train episode 154: reward = -139.80, steps = 200\n",
      "23:32:57 [DEBUG] train episode 155: reward = -394.22, steps = 200\n",
      "23:33:22 [DEBUG] train episode 156: reward = -248.95, steps = 200\n",
      "23:33:48 [DEBUG] train episode 157: reward = -257.29, steps = 200\n",
      "23:34:12 [DEBUG] train episode 158: reward = -128.74, steps = 200\n",
      "23:34:17 [DEBUG] train episode 159: reward = -130.15, steps = 200\n",
      "23:34:36 [DEBUG] train episode 160: reward = -361.81, steps = 200\n",
      "23:34:49 [DEBUG] train episode 161: reward = -136.31, steps = 200\n",
      "23:35:13 [DEBUG] train episode 162: reward = -493.46, steps = 200\n",
      "23:35:39 [DEBUG] train episode 163: reward = -253.07, steps = 200\n",
      "23:36:04 [DEBUG] train episode 164: reward = -256.73, steps = 200\n",
      "23:36:28 [DEBUG] train episode 165: reward = -132.85, steps = 200\n",
      "23:36:52 [DEBUG] train episode 166: reward = -129.08, steps = 200\n",
      "23:37:16 [DEBUG] train episode 167: reward = -507.86, steps = 200\n",
      "23:37:41 [DEBUG] train episode 168: reward = -126.42, steps = 200\n",
      "23:38:04 [DEBUG] train episode 169: reward = -249.57, steps = 200\n",
      "23:38:26 [DEBUG] train episode 170: reward = -471.17, steps = 200\n",
      "23:38:50 [DEBUG] train episode 171: reward = -126.63, steps = 200\n",
      "23:39:14 [DEBUG] train episode 172: reward = -261.44, steps = 200\n",
      "23:39:40 [DEBUG] train episode 173: reward = -455.61, steps = 200\n",
      "23:40:05 [DEBUG] train episode 174: reward = -255.64, steps = 200\n",
      "23:40:30 [DEBUG] train episode 175: reward = -361.33, steps = 200\n",
      "23:40:55 [DEBUG] train episode 176: reward = -132.19, steps = 200\n",
      "23:41:21 [DEBUG] train episode 177: reward = -509.70, steps = 200\n",
      "23:41:44 [DEBUG] train episode 178: reward = -129.24, steps = 200\n",
      "23:42:07 [DEBUG] train episode 179: reward = -248.30, steps = 200\n",
      "23:42:30 [DEBUG] train episode 180: reward = -499.05, steps = 200\n",
      "23:42:53 [DEBUG] train episode 181: reward = -127.22, steps = 200\n",
      "23:43:18 [DEBUG] train episode 182: reward = -259.56, steps = 200\n",
      "23:43:46 [DEBUG] train episode 183: reward = -385.74, steps = 200\n",
      "23:44:11 [DEBUG] train episode 184: reward = -259.06, steps = 200\n",
      "23:44:24 [DEBUG] train episode 185: reward = -267.93, steps = 200\n",
      "23:44:52 [DEBUG] train episode 186: reward = -388.39, steps = 200\n",
      "23:45:23 [DEBUG] train episode 187: reward = -22.99, steps = 200\n",
      "23:45:50 [DEBUG] train episode 188: reward = -260.05, steps = 200\n",
      "23:46:05 [DEBUG] train episode 189: reward = -148.74, steps = 200\n",
      "23:46:33 [DEBUG] train episode 190: reward = -384.37, steps = 200\n",
      "23:47:03 [DEBUG] train episode 191: reward = -763.58, steps = 200\n",
      "23:47:29 [DEBUG] train episode 192: reward = -612.00, steps = 200\n",
      "23:47:43 [DEBUG] train episode 193: reward = -744.43, steps = 200\n",
      "23:48:11 [DEBUG] train episode 194: reward = -639.91, steps = 200\n",
      "23:48:40 [DEBUG] train episode 195: reward = -639.08, steps = 200\n",
      "23:49:08 [DEBUG] train episode 196: reward = -633.09, steps = 200\n",
      "23:49:37 [DEBUG] train episode 197: reward = -694.58, steps = 200\n",
      "23:50:08 [DEBUG] train episode 198: reward = -655.34, steps = 200\n",
      "23:50:38 [DEBUG] train episode 199: reward = -518.61, steps = 200\n",
      "23:51:06 [DEBUG] train episode 200: reward = -524.62, steps = 200\n",
      "23:51:34 [DEBUG] train episode 201: reward = -614.62, steps = 200\n",
      "23:52:01 [DEBUG] train episode 202: reward = -597.74, steps = 200\n",
      "23:52:27 [DEBUG] train episode 203: reward = -537.21, steps = 200\n",
      "23:52:57 [DEBUG] train episode 204: reward = -524.72, steps = 200\n",
      "23:53:22 [DEBUG] train episode 205: reward = -519.45, steps = 200\n",
      "23:53:47 [DEBUG] train episode 206: reward = -516.54, steps = 200\n",
      "23:54:13 [DEBUG] train episode 207: reward = -511.16, steps = 200\n",
      "23:54:38 [DEBUG] train episode 208: reward = -515.56, steps = 200\n",
      "23:55:03 [DEBUG] train episode 209: reward = -515.89, steps = 200\n",
      "23:55:30 [DEBUG] train episode 210: reward = -514.13, steps = 200\n",
      "23:55:55 [DEBUG] train episode 211: reward = -507.35, steps = 200\n",
      "23:56:12 [DEBUG] train episode 212: reward = -510.10, steps = 200\n",
      "23:56:30 [DEBUG] train episode 213: reward = -493.27, steps = 200\n",
      "23:56:55 [DEBUG] train episode 214: reward = -380.58, steps = 200\n",
      "23:57:20 [DEBUG] train episode 215: reward = -271.52, steps = 200\n",
      "23:57:46 [DEBUG] train episode 216: reward = -273.14, steps = 200\n",
      "23:58:11 [DEBUG] train episode 217: reward = -387.19, steps = 200\n",
      "23:58:37 [DEBUG] train episode 218: reward = -382.29, steps = 200\n",
      "23:59:02 [DEBUG] train episode 219: reward = -513.55, steps = 200\n",
      "23:59:28 [DEBUG] train episode 220: reward = -146.44, steps = 200\n",
      "23:59:54 [DEBUG] train episode 221: reward = -154.19, steps = 200\n",
      "00:00:19 [DEBUG] train episode 222: reward = -154.21, steps = 200\n",
      "00:00:45 [DEBUG] train episode 223: reward = -376.65, steps = 200\n",
      "00:01:10 [DEBUG] train episode 224: reward = -381.46, steps = 200\n",
      "00:01:36 [DEBUG] train episode 225: reward = -145.37, steps = 200\n",
      "00:02:01 [DEBUG] train episode 226: reward = -528.42, steps = 200\n",
      "00:02:28 [DEBUG] train episode 227: reward = -258.87, steps = 200\n",
      "00:02:53 [DEBUG] train episode 228: reward = -248.90, steps = 200\n",
      "00:03:19 [DEBUG] train episode 229: reward = -7.18, steps = 200\n",
      "00:03:44 [DEBUG] train episode 230: reward = -119.35, steps = 200\n",
      "00:04:10 [DEBUG] train episode 231: reward = -123.36, steps = 200\n",
      "00:04:35 [DEBUG] train episode 232: reward = -127.87, steps = 200\n",
      "00:05:00 [DEBUG] train episode 233: reward = -5.73, steps = 200\n",
      "00:05:26 [DEBUG] train episode 234: reward = -252.92, steps = 200\n",
      "00:05:51 [DEBUG] train episode 235: reward = -353.67, steps = 200\n",
      "00:06:17 [DEBUG] train episode 236: reward = -129.10, steps = 200\n",
      "00:06:43 [DEBUG] train episode 237: reward = -136.06, steps = 200\n",
      "00:07:08 [DEBUG] train episode 238: reward = -122.32, steps = 200\n",
      "00:07:34 [DEBUG] train episode 239: reward = -122.50, steps = 200\n",
      "00:07:59 [DEBUG] train episode 240: reward = -137.85, steps = 200\n",
      "00:08:24 [DEBUG] train episode 241: reward = -343.89, steps = 200\n",
      "00:08:49 [DEBUG] train episode 242: reward = -144.32, steps = 200\n",
      "00:09:14 [DEBUG] train episode 243: reward = -134.28, steps = 200\n",
      "00:09:40 [DEBUG] train episode 244: reward = -391.44, steps = 200\n",
      "00:10:05 [DEBUG] train episode 245: reward = -15.32, steps = 200\n",
      "00:10:30 [DEBUG] train episode 246: reward = -259.59, steps = 200\n",
      "00:10:54 [DEBUG] train episode 247: reward = -251.15, steps = 200\n",
      "00:11:19 [DEBUG] train episode 248: reward = -469.47, steps = 200\n",
      "00:11:44 [DEBUG] train episode 249: reward = -267.20, steps = 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:12:09 [DEBUG] train episode 250: reward = -136.11, steps = 200\n",
      "00:12:34 [DEBUG] train episode 251: reward = -251.08, steps = 200\n",
      "00:12:59 [DEBUG] train episode 252: reward = -139.90, steps = 200\n",
      "00:13:24 [DEBUG] train episode 253: reward = -269.10, steps = 200\n",
      "00:13:49 [DEBUG] train episode 254: reward = -265.28, steps = 200\n",
      "00:14:12 [DEBUG] train episode 255: reward = -373.26, steps = 200\n",
      "00:14:34 [DEBUG] train episode 256: reward = -131.42, steps = 200\n",
      "00:14:59 [DEBUG] train episode 257: reward = -139.74, steps = 200\n",
      "00:15:24 [DEBUG] train episode 258: reward = -138.94, steps = 200\n",
      "00:15:50 [DEBUG] train episode 259: reward = -253.30, steps = 200\n",
      "00:16:15 [DEBUG] train episode 260: reward = -123.09, steps = 200\n",
      "00:16:40 [DEBUG] train episode 261: reward = -236.88, steps = 200\n",
      "00:17:05 [DEBUG] train episode 262: reward = -258.68, steps = 200\n",
      "00:17:31 [DEBUG] train episode 263: reward = -3.11, steps = 200\n",
      "00:17:56 [DEBUG] train episode 264: reward = -139.92, steps = 200\n",
      "00:18:21 [DEBUG] train episode 265: reward = -122.97, steps = 200\n",
      "00:18:46 [DEBUG] train episode 266: reward = -245.05, steps = 200\n",
      "00:19:11 [DEBUG] train episode 267: reward = -130.07, steps = 200\n",
      "00:19:37 [DEBUG] train episode 268: reward = -134.95, steps = 200\n",
      "00:20:02 [DEBUG] train episode 269: reward = -136.04, steps = 200\n",
      "00:20:28 [DEBUG] train episode 270: reward = -353.50, steps = 200\n",
      "00:20:53 [DEBUG] train episode 271: reward = -17.48, steps = 200\n",
      "00:21:18 [DEBUG] train episode 272: reward = -138.99, steps = 200\n",
      "00:21:42 [DEBUG] train episode 273: reward = -258.84, steps = 200\n",
      "00:22:07 [DEBUG] train episode 274: reward = -143.63, steps = 200\n",
      "00:22:23 [DEBUG] train episode 275: reward = -144.46, steps = 200\n",
      "00:22:40 [DEBUG] train episode 276: reward = -626.02, steps = 200\n",
      "00:23:05 [DEBUG] train episode 277: reward = -391.36, steps = 200\n",
      "00:23:29 [DEBUG] train episode 278: reward = -639.96, steps = 200\n",
      "00:23:54 [DEBUG] train episode 279: reward = -295.86, steps = 200\n",
      "00:24:20 [DEBUG] train episode 280: reward = -271.13, steps = 200\n",
      "00:24:44 [DEBUG] train episode 281: reward = -414.99, steps = 200\n",
      "00:25:10 [DEBUG] train episode 282: reward = -271.43, steps = 200\n",
      "00:25:35 [DEBUG] train episode 283: reward = -260.65, steps = 200\n",
      "00:26:00 [DEBUG] train episode 284: reward = -267.91, steps = 200\n",
      "00:26:26 [DEBUG] train episode 285: reward = -274.26, steps = 200\n",
      "00:26:51 [DEBUG] train episode 286: reward = -385.58, steps = 200\n",
      "00:27:15 [DEBUG] train episode 287: reward = -507.05, steps = 200\n",
      "00:27:41 [DEBUG] train episode 288: reward = -273.07, steps = 200\n",
      "00:28:06 [DEBUG] train episode 289: reward = -151.73, steps = 200\n",
      "00:28:31 [DEBUG] train episode 290: reward = -393.55, steps = 200\n",
      "00:28:57 [DEBUG] train episode 291: reward = -496.76, steps = 200\n",
      "00:29:24 [DEBUG] train episode 292: reward = -260.09, steps = 200\n",
      "00:29:50 [DEBUG] train episode 293: reward = -25.50, steps = 200\n",
      "00:30:15 [DEBUG] train episode 294: reward = -450.34, steps = 200\n",
      "00:30:41 [DEBUG] train episode 295: reward = -502.89, steps = 200\n",
      "00:31:06 [DEBUG] train episode 296: reward = -269.77, steps = 200\n",
      "00:31:32 [DEBUG] train episode 297: reward = -631.09, steps = 200\n",
      "00:31:58 [DEBUG] train episode 298: reward = -548.74, steps = 200\n",
      "00:32:24 [DEBUG] train episode 299: reward = -507.42, steps = 200\n",
      "00:32:50 [DEBUG] train episode 300: reward = -518.00, steps = 200\n",
      "00:33:16 [DEBUG] train episode 301: reward = -496.75, steps = 200\n",
      "00:33:41 [DEBUG] train episode 302: reward = -384.09, steps = 200\n",
      "00:34:07 [DEBUG] train episode 303: reward = -390.17, steps = 200\n",
      "00:34:33 [DEBUG] train episode 304: reward = -394.92, steps = 200\n",
      "00:34:59 [DEBUG] train episode 305: reward = -261.06, steps = 200\n",
      "00:35:24 [DEBUG] train episode 306: reward = -131.91, steps = 200\n",
      "00:35:50 [DEBUG] train episode 307: reward = -8.26, steps = 200\n",
      "00:36:15 [DEBUG] train episode 308: reward = -261.20, steps = 200\n",
      "00:36:40 [DEBUG] train episode 309: reward = -260.03, steps = 200\n",
      "00:37:05 [DEBUG] train episode 310: reward = -258.66, steps = 200\n",
      "00:37:30 [DEBUG] train episode 311: reward = -124.09, steps = 200\n",
      "00:37:55 [DEBUG] train episode 312: reward = -373.61, steps = 200\n",
      "00:38:20 [DEBUG] train episode 313: reward = -150.55, steps = 200\n",
      "00:38:45 [DEBUG] train episode 314: reward = -244.10, steps = 200\n",
      "00:39:10 [DEBUG] train episode 315: reward = -135.92, steps = 200\n",
      "00:39:35 [DEBUG] train episode 316: reward = -267.73, steps = 200\n",
      "00:40:00 [DEBUG] train episode 317: reward = -149.50, steps = 200\n",
      "00:40:25 [DEBUG] train episode 318: reward = -150.75, steps = 200\n",
      "00:40:49 [DEBUG] train episode 319: reward = -607.44, steps = 200\n",
      "00:41:14 [DEBUG] train episode 320: reward = -147.28, steps = 200\n",
      "00:41:38 [DEBUG] train episode 321: reward = -143.25, steps = 200\n",
      "00:42:03 [DEBUG] train episode 322: reward = -148.01, steps = 200\n",
      "00:42:28 [DEBUG] train episode 323: reward = -391.06, steps = 200\n",
      "00:42:52 [DEBUG] train episode 324: reward = -144.90, steps = 200\n",
      "00:43:18 [DEBUG] train episode 325: reward = -274.64, steps = 200\n",
      "00:43:44 [DEBUG] train episode 326: reward = -491.34, steps = 200\n",
      "00:44:09 [DEBUG] train episode 327: reward = -146.16, steps = 200\n",
      "00:44:34 [DEBUG] train episode 328: reward = -276.18, steps = 200\n",
      "00:45:00 [DEBUG] train episode 329: reward = -28.76, steps = 200\n",
      "00:45:26 [DEBUG] train episode 330: reward = -390.52, steps = 200\n",
      "00:45:51 [DEBUG] train episode 331: reward = -396.77, steps = 200\n",
      "00:46:16 [DEBUG] train episode 332: reward = -140.72, steps = 200\n",
      "00:46:42 [DEBUG] train episode 333: reward = -145.34, steps = 200\n",
      "00:47:07 [DEBUG] train episode 334: reward = -397.20, steps = 200\n",
      "00:47:32 [DEBUG] train episode 335: reward = -379.06, steps = 200\n",
      "00:47:58 [DEBUG] train episode 336: reward = -340.89, steps = 200\n",
      "00:48:24 [DEBUG] train episode 337: reward = -146.89, steps = 200\n",
      "00:48:42 [DEBUG] train episode 338: reward = -263.67, steps = 200\n",
      "00:48:58 [DEBUG] train episode 339: reward = -397.29, steps = 200\n",
      "00:49:14 [DEBUG] train episode 340: reward = -239.72, steps = 200\n",
      "00:49:31 [DEBUG] train episode 341: reward = -266.18, steps = 200\n",
      "00:49:48 [DEBUG] train episode 342: reward = -370.76, steps = 200\n",
      "00:50:05 [DEBUG] train episode 343: reward = -259.91, steps = 200\n",
      "00:50:22 [DEBUG] train episode 344: reward = -261.09, steps = 200\n",
      "00:50:38 [DEBUG] train episode 345: reward = -145.08, steps = 200\n",
      "00:50:55 [DEBUG] train episode 346: reward = -532.76, steps = 200\n",
      "00:51:12 [DEBUG] train episode 347: reward = -309.31, steps = 200\n",
      "00:51:29 [DEBUG] train episode 348: reward = -422.04, steps = 200\n",
      "00:51:45 [DEBUG] train episode 349: reward = -144.03, steps = 200\n",
      "00:52:02 [DEBUG] train episode 350: reward = -17.19, steps = 200\n",
      "00:52:18 [DEBUG] train episode 351: reward = -141.42, steps = 200\n",
      "00:52:35 [DEBUG] train episode 352: reward = -141.69, steps = 200\n",
      "00:52:52 [DEBUG] train episode 353: reward = -134.11, steps = 200\n",
      "00:53:09 [DEBUG] train episode 354: reward = -141.38, steps = 200\n",
      "00:53:26 [DEBUG] train episode 355: reward = -256.40, steps = 200\n",
      "00:53:42 [DEBUG] train episode 356: reward = -352.63, steps = 200\n",
      "00:53:59 [DEBUG] train episode 357: reward = -141.91, steps = 200\n",
      "00:54:16 [DEBUG] train episode 358: reward = -134.53, steps = 200\n",
      "00:54:32 [DEBUG] train episode 359: reward = -266.99, steps = 200\n",
      "00:54:48 [DEBUG] train episode 360: reward = -245.73, steps = 200\n",
      "00:55:04 [DEBUG] train episode 361: reward = -137.96, steps = 200\n",
      "00:55:21 [DEBUG] train episode 362: reward = -20.00, steps = 200\n",
      "00:55:38 [DEBUG] train episode 363: reward = -262.20, steps = 200\n",
      "00:55:55 [DEBUG] train episode 364: reward = -17.47, steps = 200\n",
      "00:56:11 [DEBUG] train episode 365: reward = -139.78, steps = 200\n",
      "00:56:28 [DEBUG] train episode 366: reward = -130.72, steps = 200\n",
      "00:56:45 [DEBUG] train episode 367: reward = -16.16, steps = 200\n",
      "00:57:01 [DEBUG] train episode 368: reward = -141.92, steps = 200\n",
      "00:57:18 [DEBUG] train episode 369: reward = -255.04, steps = 200\n",
      "00:57:35 [DEBUG] train episode 370: reward = -382.25, steps = 200\n",
      "00:57:52 [DEBUG] train episode 371: reward = -129.00, steps = 200\n",
      "00:58:08 [DEBUG] train episode 372: reward = -243.17, steps = 200\n",
      "00:58:25 [DEBUG] train episode 373: reward = -145.24, steps = 200\n",
      "00:58:42 [DEBUG] train episode 374: reward = -258.07, steps = 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:58:58 [DEBUG] train episode 375: reward = -259.12, steps = 200\n",
      "00:59:14 [DEBUG] train episode 376: reward = -146.94, steps = 200\n",
      "00:59:31 [DEBUG] train episode 377: reward = -608.53, steps = 200\n",
      "00:59:47 [DEBUG] train episode 378: reward = -543.75, steps = 200\n",
      "01:00:04 [DEBUG] train episode 379: reward = -742.49, steps = 200\n",
      "01:00:21 [DEBUG] train episode 380: reward = -629.05, steps = 200\n",
      "01:00:38 [DEBUG] train episode 381: reward = -774.39, steps = 200\n",
      "01:00:54 [DEBUG] train episode 382: reward = -639.40, steps = 200\n",
      "01:01:11 [DEBUG] train episode 383: reward = -648.67, steps = 200\n",
      "01:01:27 [DEBUG] train episode 384: reward = -644.23, steps = 200\n",
      "01:01:44 [DEBUG] train episode 385: reward = -642.93, steps = 200\n",
      "01:02:00 [DEBUG] train episode 386: reward = -668.29, steps = 200\n",
      "01:02:17 [DEBUG] train episode 387: reward = -847.12, steps = 200\n",
      "01:02:35 [DEBUG] train episode 388: reward = -632.46, steps = 200\n",
      "01:02:51 [DEBUG] train episode 389: reward = -269.30, steps = 200\n",
      "01:03:08 [DEBUG] train episode 390: reward = -369.55, steps = 200\n",
      "01:03:24 [DEBUG] train episode 391: reward = -21.70, steps = 200\n",
      "01:03:41 [DEBUG] train episode 392: reward = -142.20, steps = 200\n",
      "01:03:58 [DEBUG] train episode 393: reward = -254.55, steps = 200\n",
      "01:04:15 [DEBUG] train episode 394: reward = -261.36, steps = 200\n",
      "01:04:31 [DEBUG] train episode 395: reward = -136.87, steps = 200\n",
      "01:04:48 [DEBUG] train episode 396: reward = -379.53, steps = 200\n",
      "01:05:05 [DEBUG] train episode 397: reward = -253.23, steps = 200\n",
      "01:05:22 [DEBUG] train episode 398: reward = -126.21, steps = 200\n",
      "01:05:39 [DEBUG] train episode 399: reward = -138.09, steps = 200\n",
      "01:05:55 [DEBUG] train episode 400: reward = -139.17, steps = 200\n",
      "01:06:12 [DEBUG] train episode 401: reward = -269.17, steps = 200\n",
      "01:06:28 [DEBUG] train episode 402: reward = -137.38, steps = 200\n",
      "01:06:45 [DEBUG] train episode 403: reward = -12.78, steps = 200\n",
      "01:07:01 [DEBUG] train episode 404: reward = -241.24, steps = 200\n",
      "01:07:18 [DEBUG] train episode 405: reward = -136.22, steps = 200\n",
      "01:07:34 [DEBUG] train episode 406: reward = -260.51, steps = 200\n",
      "01:07:51 [DEBUG] train episode 407: reward = -18.64, steps = 200\n",
      "01:08:08 [DEBUG] train episode 408: reward = -132.82, steps = 200\n",
      "01:08:25 [DEBUG] train episode 409: reward = -252.53, steps = 200\n",
      "01:08:41 [DEBUG] train episode 410: reward = -143.07, steps = 200\n",
      "01:08:57 [DEBUG] train episode 411: reward = -134.18, steps = 200\n",
      "01:09:05 [DEBUG] train episode 412: reward = -142.69, steps = 200\n",
      "01:09:21 [DEBUG] train episode 413: reward = -261.22, steps = 200\n",
      "01:09:38 [DEBUG] train episode 414: reward = -144.43, steps = 200\n",
      "01:09:54 [DEBUG] train episode 415: reward = -141.89, steps = 200\n",
      "01:10:11 [DEBUG] train episode 416: reward = -266.33, steps = 200\n",
      "01:10:27 [DEBUG] train episode 417: reward = -418.36, steps = 200\n",
      "01:10:44 [DEBUG] train episode 418: reward = -254.11, steps = 200\n",
      "01:11:01 [DEBUG] train episode 419: reward = -256.19, steps = 200\n",
      "01:11:18 [DEBUG] train episode 420: reward = -140.74, steps = 200\n",
      "01:11:34 [DEBUG] train episode 421: reward = -145.51, steps = 200\n",
      "01:11:51 [DEBUG] train episode 422: reward = -148.77, steps = 200\n",
      "01:12:08 [DEBUG] train episode 423: reward = -139.98, steps = 200\n",
      "01:12:25 [DEBUG] train episode 424: reward = -263.26, steps = 200\n",
      "01:12:41 [DEBUG] train episode 425: reward = -147.96, steps = 200\n",
      "01:12:58 [DEBUG] train episode 426: reward = -272.64, steps = 200\n",
      "01:13:15 [DEBUG] train episode 427: reward = -264.31, steps = 200\n",
      "01:13:32 [DEBUG] train episode 428: reward = -268.95, steps = 200\n",
      "01:13:49 [DEBUG] train episode 429: reward = -269.61, steps = 200\n",
      "01:14:06 [DEBUG] train episode 430: reward = -268.88, steps = 200\n",
      "01:14:23 [DEBUG] train episode 431: reward = -380.16, steps = 200\n",
      "01:14:39 [DEBUG] train episode 432: reward = -151.17, steps = 200\n",
      "01:14:56 [DEBUG] train episode 433: reward = -395.47, steps = 200\n",
      "01:15:13 [DEBUG] train episode 434: reward = -264.33, steps = 200\n",
      "01:15:29 [DEBUG] train episode 435: reward = -147.88, steps = 200\n",
      "01:15:45 [DEBUG] train episode 436: reward = -268.07, steps = 200\n",
      "01:16:01 [DEBUG] train episode 437: reward = -266.89, steps = 200\n",
      "01:16:17 [DEBUG] train episode 438: reward = -257.11, steps = 200\n",
      "01:16:33 [DEBUG] train episode 439: reward = -376.24, steps = 200\n",
      "01:16:49 [DEBUG] train episode 440: reward = -267.07, steps = 200\n",
      "01:17:04 [DEBUG] train episode 441: reward = -268.96, steps = 200\n",
      "01:17:20 [DEBUG] train episode 442: reward = -383.02, steps = 200\n",
      "01:17:35 [DEBUG] train episode 443: reward = -272.87, steps = 200\n",
      "01:17:52 [DEBUG] train episode 444: reward = -263.23, steps = 200\n",
      "01:18:08 [DEBUG] train episode 445: reward = -144.50, steps = 200\n",
      "01:18:23 [DEBUG] train episode 446: reward = -261.81, steps = 200\n",
      "01:18:39 [DEBUG] train episode 447: reward = -147.03, steps = 200\n",
      "01:18:54 [DEBUG] train episode 448: reward = -252.47, steps = 200\n",
      "01:19:10 [DEBUG] train episode 449: reward = -150.22, steps = 200\n",
      "01:19:26 [DEBUG] train episode 450: reward = -269.16, steps = 200\n",
      "01:19:42 [DEBUG] train episode 451: reward = -274.76, steps = 200\n",
      "01:19:58 [DEBUG] train episode 452: reward = -151.32, steps = 200\n",
      "01:20:14 [DEBUG] train episode 453: reward = -273.90, steps = 200\n",
      "01:20:29 [DEBUG] train episode 454: reward = -148.32, steps = 200\n",
      "01:20:45 [DEBUG] train episode 455: reward = -169.58, steps = 200\n",
      "01:21:00 [DEBUG] train episode 456: reward = -379.57, steps = 200\n",
      "01:21:16 [DEBUG] train episode 457: reward = -260.86, steps = 200\n",
      "01:21:32 [DEBUG] train episode 458: reward = -275.66, steps = 200\n",
      "01:21:48 [DEBUG] train episode 459: reward = -274.39, steps = 200\n",
      "01:22:04 [DEBUG] train episode 460: reward = -141.30, steps = 200\n",
      "01:22:20 [DEBUG] train episode 461: reward = -276.17, steps = 200\n",
      "01:22:35 [DEBUG] train episode 462: reward = -30.32, steps = 200\n",
      "01:22:51 [DEBUG] train episode 463: reward = -143.40, steps = 200\n",
      "01:23:07 [DEBUG] train episode 464: reward = -402.00, steps = 200\n",
      "01:23:23 [DEBUG] train episode 465: reward = -149.61, steps = 200\n",
      "01:23:39 [DEBUG] train episode 466: reward = -149.87, steps = 200\n",
      "01:23:55 [DEBUG] train episode 467: reward = -155.11, steps = 200\n",
      "01:24:11 [DEBUG] train episode 468: reward = -389.36, steps = 200\n",
      "01:24:26 [DEBUG] train episode 469: reward = -148.41, steps = 200\n",
      "01:24:42 [DEBUG] train episode 470: reward = -255.07, steps = 200\n",
      "01:24:58 [DEBUG] train episode 471: reward = -139.80, steps = 200\n",
      "01:25:15 [DEBUG] train episode 472: reward = -274.99, steps = 200\n",
      "01:25:31 [DEBUG] train episode 473: reward = -507.31, steps = 200\n",
      "01:25:47 [DEBUG] train episode 474: reward = -510.17, steps = 200\n",
      "01:26:03 [DEBUG] train episode 475: reward = -148.08, steps = 200\n",
      "01:26:19 [DEBUG] train episode 476: reward = -415.33, steps = 200\n",
      "01:26:34 [DEBUG] train episode 477: reward = -389.40, steps = 200\n",
      "01:26:50 [DEBUG] train episode 478: reward = -271.82, steps = 200\n",
      "01:27:06 [DEBUG] train episode 479: reward = -507.72, steps = 200\n",
      "01:27:22 [DEBUG] train episode 480: reward = -277.82, steps = 200\n",
      "01:27:38 [DEBUG] train episode 481: reward = -399.22, steps = 200\n",
      "01:27:53 [DEBUG] train episode 482: reward = -398.20, steps = 200\n",
      "01:28:09 [DEBUG] train episode 483: reward = -383.57, steps = 200\n",
      "01:28:25 [DEBUG] train episode 484: reward = -511.74, steps = 200\n",
      "01:28:41 [DEBUG] train episode 485: reward = -392.74, steps = 200\n",
      "01:28:56 [DEBUG] train episode 486: reward = -272.94, steps = 200\n",
      "01:29:09 [DEBUG] train episode 487: reward = -262.63, steps = 200\n",
      "01:29:16 [DEBUG] train episode 488: reward = -368.21, steps = 200\n",
      "01:29:21 [DEBUG] train episode 489: reward = -264.77, steps = 200\n",
      "01:29:27 [DEBUG] train episode 490: reward = -263.46, steps = 200\n",
      "01:29:32 [DEBUG] train episode 491: reward = -254.84, steps = 200\n",
      "01:29:37 [DEBUG] train episode 492: reward = -146.42, steps = 200\n",
      "01:29:43 [DEBUG] train episode 493: reward = -139.18, steps = 200\n",
      "01:29:48 [DEBUG] train episode 494: reward = -255.88, steps = 200\n",
      "01:29:53 [DEBUG] train episode 495: reward = -143.80, steps = 200\n",
      "01:30:00 [DEBUG] train episode 496: reward = -147.65, steps = 200\n",
      "01:30:05 [DEBUG] train episode 497: reward = -150.42, steps = 200\n",
      "01:30:10 [DEBUG] train episode 498: reward = -144.92, steps = 200\n",
      "01:30:15 [DEBUG] train episode 499: reward = -100.70, steps = 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:30:20 [DEBUG] train episode 500: reward = -139.33, steps = 200\n",
      "01:30:26 [DEBUG] train episode 501: reward = -354.08, steps = 200\n",
      "01:30:31 [DEBUG] train episode 502: reward = -377.33, steps = 200\n",
      "01:30:37 [DEBUG] train episode 503: reward = -498.05, steps = 200\n",
      "01:30:42 [DEBUG] train episode 504: reward = -150.70, steps = 200\n",
      "01:30:48 [DEBUG] train episode 505: reward = -270.16, steps = 200\n",
      "01:30:53 [DEBUG] train episode 506: reward = -398.42, steps = 200\n",
      "01:30:58 [DEBUG] train episode 507: reward = -273.39, steps = 200\n",
      "01:31:04 [DEBUG] train episode 508: reward = -263.52, steps = 200\n",
      "01:31:09 [DEBUG] train episode 509: reward = -274.01, steps = 200\n",
      "01:31:14 [DEBUG] train episode 510: reward = -150.39, steps = 200\n",
      "01:31:20 [DEBUG] train episode 511: reward = -289.59, steps = 200\n",
      "01:31:25 [DEBUG] train episode 512: reward = -260.72, steps = 200\n",
      "01:31:30 [DEBUG] train episode 513: reward = -380.82, steps = 200\n",
      "01:31:35 [DEBUG] train episode 514: reward = -151.76, steps = 200\n",
      "01:31:41 [DEBUG] train episode 515: reward = -258.52, steps = 200\n",
      "01:31:46 [DEBUG] train episode 516: reward = -148.96, steps = 200\n",
      "01:31:51 [DEBUG] train episode 517: reward = -149.84, steps = 200\n",
      "01:31:57 [DEBUG] train episode 518: reward = -258.24, steps = 200\n",
      "01:32:02 [DEBUG] train episode 519: reward = -149.32, steps = 200\n",
      "01:32:08 [DEBUG] train episode 520: reward = -148.45, steps = 200\n",
      "01:32:13 [DEBUG] train episode 521: reward = -263.63, steps = 200\n",
      "01:32:18 [DEBUG] train episode 522: reward = -29.91, steps = 200\n",
      "01:32:24 [DEBUG] train episode 523: reward = -381.51, steps = 200\n",
      "01:32:29 [DEBUG] train episode 524: reward = -151.17, steps = 200\n",
      "01:32:35 [DEBUG] train episode 525: reward = -388.57, steps = 200\n",
      "01:32:40 [DEBUG] train episode 526: reward = -265.23, steps = 200\n",
      "01:32:46 [DEBUG] train episode 527: reward = -144.27, steps = 200\n",
      "01:32:51 [DEBUG] train episode 528: reward = -263.10, steps = 200\n",
      "01:32:57 [DEBUG] train episode 529: reward = -373.26, steps = 200\n",
      "01:33:02 [DEBUG] train episode 530: reward = -555.69, steps = 200\n",
      "01:33:08 [DEBUG] train episode 531: reward = -263.56, steps = 200\n",
      "01:33:13 [DEBUG] train episode 532: reward = -425.68, steps = 200\n",
      "01:33:19 [DEBUG] train episode 533: reward = -251.18, steps = 200\n",
      "01:33:24 [DEBUG] train episode 534: reward = -498.53, steps = 200\n",
      "01:33:30 [DEBUG] train episode 535: reward = -356.62, steps = 200\n",
      "01:33:35 [DEBUG] train episode 536: reward = -143.89, steps = 200\n",
      "01:33:40 [DEBUG] train episode 537: reward = -265.51, steps = 200\n",
      "01:33:46 [DEBUG] train episode 538: reward = -269.74, steps = 200\n",
      "01:33:52 [DEBUG] train episode 539: reward = -270.57, steps = 200\n",
      "01:33:57 [DEBUG] train episode 540: reward = -266.85, steps = 200\n",
      "01:34:02 [DEBUG] train episode 541: reward = -376.09, steps = 200\n",
      "01:34:08 [DEBUG] train episode 542: reward = -329.94, steps = 200\n",
      "01:34:13 [DEBUG] train episode 543: reward = -503.20, steps = 200\n",
      "01:34:18 [DEBUG] train episode 544: reward = -259.40, steps = 200\n",
      "01:34:23 [DEBUG] train episode 545: reward = -257.96, steps = 200\n",
      "01:34:28 [DEBUG] train episode 546: reward = -264.31, steps = 200\n",
      "01:34:34 [DEBUG] train episode 547: reward = -143.05, steps = 200\n",
      "01:34:40 [DEBUG] train episode 548: reward = -275.63, steps = 200\n",
      "01:34:45 [DEBUG] train episode 549: reward = -138.09, steps = 200\n",
      "01:34:51 [DEBUG] train episode 550: reward = -260.49, steps = 200\n",
      "01:34:56 [DEBUG] train episode 551: reward = -253.44, steps = 200\n",
      "01:35:02 [DEBUG] train episode 552: reward = -142.70, steps = 200\n",
      "01:35:07 [DEBUG] train episode 553: reward = -257.85, steps = 200\n",
      "01:35:12 [DEBUG] train episode 554: reward = -379.59, steps = 200\n",
      "01:35:18 [DEBUG] train episode 555: reward = -374.35, steps = 200\n",
      "01:35:23 [DEBUG] train episode 556: reward = -388.28, steps = 200\n",
      "01:35:28 [DEBUG] train episode 557: reward = -407.52, steps = 200\n",
      "01:35:33 [DEBUG] train episode 558: reward = -365.87, steps = 200\n",
      "01:35:38 [DEBUG] train episode 559: reward = -141.48, steps = 200\n",
      "01:35:44 [DEBUG] train episode 560: reward = -378.74, steps = 200\n",
      "01:35:49 [DEBUG] train episode 561: reward = -9.17, steps = 200\n",
      "01:35:55 [DEBUG] train episode 562: reward = -390.40, steps = 200\n",
      "01:36:00 [DEBUG] train episode 563: reward = -405.60, steps = 200\n",
      "01:36:06 [DEBUG] train episode 564: reward = -257.15, steps = 200\n",
      "01:36:11 [DEBUG] train episode 565: reward = -9.44, steps = 200\n",
      "01:36:17 [DEBUG] train episode 566: reward = -137.65, steps = 200\n",
      "01:36:22 [DEBUG] train episode 567: reward = -135.17, steps = 200\n",
      "01:36:28 [DEBUG] train episode 568: reward = -272.75, steps = 200\n",
      "01:36:34 [DEBUG] train episode 569: reward = -266.22, steps = 200\n",
      "01:36:39 [DEBUG] train episode 570: reward = -245.16, steps = 200\n",
      "01:36:44 [DEBUG] train episode 571: reward = -379.56, steps = 200\n",
      "01:36:50 [DEBUG] train episode 572: reward = -15.84, steps = 200\n",
      "01:36:56 [DEBUG] train episode 573: reward = -128.26, steps = 200\n",
      "01:37:01 [DEBUG] train episode 574: reward = -15.93, steps = 200\n",
      "01:37:07 [DEBUG] train episode 575: reward = -123.62, steps = 200\n",
      "01:37:12 [DEBUG] train episode 576: reward = -132.33, steps = 200\n",
      "01:37:18 [DEBUG] train episode 577: reward = -250.70, steps = 200\n",
      "01:37:24 [DEBUG] train episode 578: reward = -136.48, steps = 200\n",
      "01:37:29 [DEBUG] train episode 579: reward = -129.15, steps = 200\n",
      "01:37:34 [DEBUG] train episode 580: reward = -233.53, steps = 200\n",
      "01:37:39 [DEBUG] train episode 581: reward = -237.71, steps = 200\n",
      "01:37:45 [DEBUG] train episode 582: reward = -351.62, steps = 200\n",
      "01:37:50 [DEBUG] train episode 583: reward = -258.86, steps = 200\n",
      "01:37:55 [DEBUG] train episode 584: reward = -124.89, steps = 200\n",
      "01:38:01 [DEBUG] train episode 585: reward = -7.27, steps = 200\n",
      "01:38:06 [DEBUG] train episode 586: reward = -133.13, steps = 200\n",
      "01:38:11 [DEBUG] train episode 587: reward = -2.93, steps = 200\n",
      "01:38:17 [DEBUG] train episode 588: reward = -230.33, steps = 200\n",
      "01:38:22 [DEBUG] train episode 589: reward = -2.20, steps = 200\n",
      "01:38:27 [DEBUG] train episode 590: reward = -244.70, steps = 200\n",
      "01:38:33 [DEBUG] train episode 591: reward = -122.70, steps = 200\n",
      "01:38:38 [DEBUG] train episode 592: reward = -2.04, steps = 200\n",
      "01:38:38 [INFO] ==== test ====\n",
      "01:38:38 [DEBUG] test episode 0: reward = -261.33, steps = 200\n",
      "01:38:38 [DEBUG] test episode 1: reward = -118.75, steps = 200\n",
      "01:38:38 [DEBUG] test episode 2: reward = -125.43, steps = 200\n",
      "01:38:38 [DEBUG] test episode 3: reward = -125.14, steps = 200\n",
      "01:38:39 [DEBUG] test episode 4: reward = -128.00, steps = 200\n",
      "01:38:39 [DEBUG] test episode 5: reward = -235.12, steps = 200\n",
      "01:38:39 [DEBUG] test episode 6: reward = -121.45, steps = 200\n",
      "01:38:39 [DEBUG] test episode 7: reward = -0.15, steps = 200\n",
      "01:38:39 [DEBUG] test episode 8: reward = -115.91, steps = 200\n",
      "01:38:39 [DEBUG] test episode 9: reward = -321.16, steps = 200\n",
      "01:38:39 [DEBUG] test episode 10: reward = -251.45, steps = 200\n",
      "01:38:39 [DEBUG] test episode 11: reward = -127.13, steps = 200\n",
      "01:38:39 [DEBUG] test episode 12: reward = -0.46, steps = 200\n",
      "01:38:40 [DEBUG] test episode 13: reward = -246.57, steps = 200\n",
      "01:38:40 [DEBUG] test episode 14: reward = -2.71, steps = 200\n",
      "01:38:40 [DEBUG] test episode 15: reward = -124.43, steps = 200\n",
      "01:38:40 [DEBUG] test episode 16: reward = -243.26, steps = 200\n",
      "01:38:40 [DEBUG] test episode 17: reward = -232.85, steps = 200\n",
      "01:38:40 [DEBUG] test episode 18: reward = -1.44, steps = 200\n",
      "01:38:40 [DEBUG] test episode 19: reward = -123.66, steps = 200\n",
      "01:38:40 [DEBUG] test episode 20: reward = -237.24, steps = 200\n",
      "01:38:40 [DEBUG] test episode 21: reward = -1.29, steps = 200\n",
      "01:38:40 [DEBUG] test episode 22: reward = -126.91, steps = 200\n",
      "01:38:41 [DEBUG] test episode 23: reward = -116.32, steps = 200\n",
      "01:38:41 [DEBUG] test episode 24: reward = -118.83, steps = 200\n",
      "01:38:41 [DEBUG] test episode 25: reward = -237.42, steps = 200\n",
      "01:38:41 [DEBUG] test episode 26: reward = -241.57, steps = 200\n",
      "01:38:41 [DEBUG] test episode 27: reward = -124.72, steps = 200\n",
      "01:38:41 [DEBUG] test episode 28: reward = -123.58, steps = 200\n",
      "01:38:41 [DEBUG] test episode 29: reward = -124.87, steps = 200\n",
      "01:38:41 [DEBUG] test episode 30: reward = -125.79, steps = 200\n",
      "01:38:41 [DEBUG] test episode 31: reward = -230.48, steps = 200\n",
      "01:38:41 [DEBUG] test episode 32: reward = -116.64, steps = 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:38:42 [DEBUG] test episode 33: reward = -0.16, steps = 200\n",
      "01:38:42 [DEBUG] test episode 34: reward = -228.79, steps = 200\n",
      "01:38:42 [DEBUG] test episode 35: reward = -125.48, steps = 200\n",
      "01:38:42 [DEBUG] test episode 36: reward = -116.75, steps = 200\n",
      "01:38:42 [DEBUG] test episode 37: reward = -0.31, steps = 200\n",
      "01:38:42 [DEBUG] test episode 38: reward = -119.24, steps = 200\n",
      "01:38:42 [DEBUG] test episode 39: reward = -1.38, steps = 200\n",
      "01:38:42 [DEBUG] test episode 40: reward = -0.36, steps = 200\n",
      "01:38:42 [DEBUG] test episode 41: reward = -7.04, steps = 200\n",
      "01:38:42 [DEBUG] test episode 42: reward = -124.34, steps = 200\n",
      "01:38:43 [DEBUG] test episode 43: reward = -121.50, steps = 200\n",
      "01:38:43 [DEBUG] test episode 44: reward = -116.98, steps = 200\n",
      "01:38:43 [DEBUG] test episode 45: reward = -124.94, steps = 200\n",
      "01:38:43 [DEBUG] test episode 46: reward = -247.80, steps = 200\n",
      "01:38:43 [DEBUG] test episode 47: reward = -116.90, steps = 200\n",
      "01:38:43 [DEBUG] test episode 48: reward = -122.59, steps = 200\n",
      "01:38:43 [DEBUG] test episode 49: reward = -234.89, steps = 200\n",
      "01:38:43 [DEBUG] test episode 50: reward = -124.66, steps = 200\n",
      "01:38:43 [DEBUG] test episode 51: reward = -117.62, steps = 200\n",
      "01:38:43 [DEBUG] test episode 52: reward = -119.23, steps = 200\n",
      "01:38:44 [DEBUG] test episode 53: reward = -121.89, steps = 200\n",
      "01:38:44 [DEBUG] test episode 54: reward = -125.16, steps = 200\n",
      "01:38:44 [DEBUG] test episode 55: reward = -114.38, steps = 200\n",
      "01:38:44 [DEBUG] test episode 56: reward = -0.56, steps = 200\n",
      "01:38:44 [DEBUG] test episode 57: reward = -241.61, steps = 200\n",
      "01:38:44 [DEBUG] test episode 58: reward = -234.53, steps = 200\n",
      "01:38:44 [DEBUG] test episode 59: reward = -334.53, steps = 200\n",
      "01:38:44 [DEBUG] test episode 60: reward = -120.47, steps = 200\n",
      "01:38:44 [DEBUG] test episode 61: reward = -124.77, steps = 200\n",
      "01:38:45 [DEBUG] test episode 62: reward = -0.08, steps = 200\n",
      "01:38:45 [DEBUG] test episode 63: reward = -255.07, steps = 200\n",
      "01:38:45 [DEBUG] test episode 64: reward = -226.59, steps = 200\n",
      "01:38:45 [DEBUG] test episode 65: reward = -123.60, steps = 200\n",
      "01:38:45 [DEBUG] test episode 66: reward = -0.20, steps = 200\n",
      "01:38:45 [DEBUG] test episode 67: reward = -242.10, steps = 200\n",
      "01:38:45 [DEBUG] test episode 68: reward = -128.87, steps = 200\n",
      "01:38:45 [DEBUG] test episode 69: reward = -238.31, steps = 200\n",
      "01:38:45 [DEBUG] test episode 70: reward = -124.36, steps = 200\n",
      "01:38:45 [DEBUG] test episode 71: reward = -247.18, steps = 200\n",
      "01:38:46 [DEBUG] test episode 72: reward = -124.74, steps = 200\n",
      "01:38:46 [DEBUG] test episode 73: reward = -118.53, steps = 200\n",
      "01:38:46 [DEBUG] test episode 74: reward = -341.79, steps = 200\n",
      "01:38:46 [DEBUG] test episode 75: reward = -0.60, steps = 200\n",
      "01:38:46 [DEBUG] test episode 76: reward = -7.49, steps = 200\n",
      "01:38:46 [DEBUG] test episode 77: reward = -248.30, steps = 200\n",
      "01:38:46 [DEBUG] test episode 78: reward = -118.03, steps = 200\n",
      "01:38:46 [DEBUG] test episode 79: reward = -124.20, steps = 200\n",
      "01:38:46 [DEBUG] test episode 80: reward = -120.89, steps = 200\n",
      "01:38:46 [DEBUG] test episode 81: reward = -120.66, steps = 200\n",
      "01:38:47 [DEBUG] test episode 82: reward = -117.17, steps = 200\n",
      "01:38:47 [DEBUG] test episode 83: reward = -328.55, steps = 200\n",
      "01:38:47 [DEBUG] test episode 84: reward = -3.19, steps = 200\n",
      "01:38:47 [DEBUG] test episode 85: reward = -123.96, steps = 200\n",
      "01:38:47 [DEBUG] test episode 86: reward = -332.92, steps = 200\n",
      "01:38:47 [DEBUG] test episode 87: reward = -126.92, steps = 200\n",
      "01:38:47 [DEBUG] test episode 88: reward = -126.21, steps = 200\n",
      "01:38:47 [DEBUG] test episode 89: reward = -120.01, steps = 200\n",
      "01:38:47 [DEBUG] test episode 90: reward = -244.66, steps = 200\n",
      "01:38:47 [DEBUG] test episode 91: reward = -123.42, steps = 200\n",
      "01:38:48 [DEBUG] test episode 92: reward = -0.01, steps = 200\n",
      "01:38:48 [DEBUG] test episode 93: reward = -0.21, steps = 200\n",
      "01:38:48 [DEBUG] test episode 94: reward = -1.46, steps = 200\n",
      "01:38:48 [DEBUG] test episode 95: reward = -350.35, steps = 200\n",
      "01:38:48 [DEBUG] test episode 96: reward = -238.15, steps = 200\n",
      "01:38:48 [DEBUG] test episode 97: reward = -338.92, steps = 200\n",
      "01:38:48 [DEBUG] test episode 98: reward = -116.32, steps = 200\n",
      "01:38:48 [DEBUG] test episode 99: reward = -1.09, steps = 200\n",
      "01:38:48 [INFO] average episode reward = -140.26  95.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def play_episode(env, agent, max_episode_steps=None, mode=None, render=False):\n",
    "    observation, reward, done = env.reset(), 0., False\n",
    "    agent.reset(mode=mode)\n",
    "    episode_reward, elapsed_steps = 0., 0\n",
    "    while True:\n",
    "        action = agent.step(observation, reward, done)\n",
    "        if render:\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        elapsed_steps += 1\n",
    "        if max_episode_steps and elapsed_steps >= max_episode_steps:\n",
    "            break\n",
    "    agent.close()\n",
    "    return episode_reward, elapsed_steps\n",
    "\n",
    "\n",
    "logging.info('==== train ====')\n",
    "episode_rewards = []\n",
    "for episode in itertools.count():\n",
    "    episode_reward, elapsed_steps = play_episode(env.unwrapped, agent,\n",
    "            max_episode_steps=env._max_episode_steps, mode='train')\n",
    "    episode_rewards.append(episode_reward)\n",
    "    logging.debug('train episode %d: reward = %.2f, steps = %d',\n",
    "            episode, episode_reward, elapsed_steps)\n",
    "    if np.mean(episode_rewards[-10:]) > -120:\n",
    "        break\n",
    "plt.plot(episode_rewards)\n",
    "\n",
    "\n",
    "logging.info('==== test ====')\n",
    "episode_rewards = []\n",
    "for episode in range(100):\n",
    "    episode_reward, elapsed_steps = play_episode(env, agent)\n",
    "    episode_rewards.append(episode_reward)\n",
    "    logging.debug('test episode %d: reward = %.2f, steps = %d',\n",
    "            episode, episode_reward, elapsed_steps)\n",
    "logging.info('average episode reward = %.2f  %.2f',\n",
    "        np.mean(episode_rewards), np.std(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
